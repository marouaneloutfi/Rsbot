{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://www.group-cva.com/wp-content/themes/group_cva/media/logo_cva.svg)\n",
    "# Deep Learning in Remote Sensing\n",
    "### Introduction to <span style=\"color: #B48C4E\">Rsbot</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is <span style=\"color: #B48C4E\">Rsbot</span>?\n",
    "\n",
    "**_Rsbot is a python module designed to make Remote sensing with Google Earth Engine a lot easier._**\n",
    "    \n",
    "**_With extensibility at its core, Rsbot is a practical solution to building deeplearning pipelines._**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Main Features:\n",
    "* Construct Datasets arround Satellite imagery\n",
    "* Provides ready to use deep learning models\n",
    "* . . .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cropland classification demo\n",
    "\n",
    "**The Goal of this example is to identify crop types in fields using <span style=\"color: #B48C4E\">Landsat8</span> satellite imagery.**\\\n",
    "**The architecture of our example is as follows**\n",
    "![architecture](https://raw.githubusercontent.com/marouaneloutfi/Rsbot/master/notebooks/images/architecture1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_First we clone the github repository and install the required dependencies_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/marouaneloutfi/Rsbot.git\n",
    "!pip install -r Rsbot/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Import the classes and method we will be using for the Demo_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from Rsbot.gee.core import Gee, Landsat8\n",
    "from Rsbot.gee.crops import Crops\n",
    "from Rsbot.gee.utils import temp_concatenate\n",
    "from Rsbot.gee.dataset import Dataset\n",
    "from Rsbot.models.unet_3d import Unet3D\n",
    "from Rsbot.gee.tf_io import TfDatasetParser, binary_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Initialize and authenticate to google earth engine through <span style=\"color: #B48C4E\">Rsbot</span> Gee Class_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gee = Gee.get_instance(Auth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Create a Landsat8 object to access and transform the Lansat8 satellite imagery_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "landsat = Landsat8('LANDSAT/LC08/C01/T1_SR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_The module should also come with a pre-defined wrapper classes for some popular Earth Engine datasets,\n",
    "For now we Have only one Dataset ready to use which is the [USDA](https://developers.google.com/earth-engine/datasets/catalog/USDA_NASS_CDL) NASS Cropland Data Layers._**\n",
    "\n",
    "\n",
    "**_This Data layer describes for each year  the crop-specific land cover of the entire country of  United States.\n",
    "for the purposes of this example, we are using the 2017 cropland layer to train our model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "crops = Crops(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_The USDA Cropland dataset comes with 254 predefined crop types._**\n",
    "\n",
    "\n",
    "**_In this example we want to train our model to identify 5 types only:_**\n",
    "\n",
    "    Corn, Soybeans, Alfalfa, Wheat and the Forrest landcover as well\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['corn', 'soybeans', 'alfalfa', 'wheat', 'forrest', 'background']\n",
    "crops_labels = crops.filter_labels(labels, thresh=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_To take into account the temporal changes that plants go through during their agricultral cycle,\n",
    "We use the following function to concatenate the satellite images of an 8 months period (an image for each month) and couple them with the landcover mask at the end._**\n",
    "\n",
    "\n",
    "**_The result is a GEE image of 64 bands (8 landsat bands * 8 monts ) plus the 6 labels_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "temporal_image = temp_concatenate(landsat, crops_labels, year=2017, kernel_size=KERNEL_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_We take two rectangular geometries each corresding to a geographical region in the United states and We use them to  create  our training and validation datasets by randomly sampling the previous GEE image over these regions_**\n",
    "![geomtries](https://raw.githubusercontent.com/marouaneloutfi/Rsbot/master/notebooks/images/geoms.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(temporal_image, TRAINING_RECTANGLE, density=(0.5, 0.5), export_size=30)\n",
    "val_dataset = Dataset(temporal_image, VALIDATION_RECTANGLE, density=(0.1, 0.1), export_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Now that we have our datasets, we can iterate over them to download the samples directly to our Google drive account in mini batches as Tensorflow records._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, samples in  enumerate(iter(val_dataset)):\n",
    "    val_dataset.export_to_drive(samples, '', 'val_shard_'+str(i), folder=\"validation_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_We can check the status of the batches with the following lines_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for batch in val_dataset.batches:\n",
    "    print([batch.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Once all of our samples have been downloaded as TF records. we load them into memorry as ready to use tensorflow Datasets using the Class TfDatasetParser_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/content/drive/My Drive/train_example/*.tfrecord.gz'\n",
    "val_dir = '/content/drive/My Drive/validation_example/*.tfrecord.gz'\n",
    "\n",
    "tf_parser = TfDatasetParser(KERNEL_SIZE, labels)\n",
    "\n",
    "train = tf_parser.get_dataset(train_dir, KERNEL_SIZE, shuffle=True)\n",
    "validation = tf_parser.get_dataset(val_dir, KERNEL_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Rsbot should come equipped with some popular segmentation and classification models. at the time of writing, Only 2 models have been implemented in Rsbot, both based on the Ecoder-decoder Unet archtitecture for sematic segmentation_**\n",
    "\n",
    "**_We initialize our Neural Network Model <span style=\"color: #B48C4E\">UNET 3D</span>._**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (KERNEL_SIZE, KERNEL_SIZE, N_BANDS, N_MONTHS) # 256x256x8x8\n",
    "\n",
    "unet_3d = Unet3D(input_shape, n_base_filters=8, num_classes=6, dropout=0.05,\n",
    "               depth=3, pool_shape=(2, 2, 2))\n",
    "\n",
    "model = unet_3d.get_model(final_activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Initialize callbacks to tune and auto-save model weights upon val loss imporvement during training_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ModelCheckpoint('/content/drive/My Drive/mymodels_weights.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**_Compile the Model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Start the training process of our Model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = model.fit(train, steps_per_epoch=100 , epochs=200, callbacks=callbacks,\n",
    "                validation_data=validation, validation_steps = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Once the training process is done, we can visualise the results of the segmentation using  built-in functions such as binairy mask binary_mask()_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(myinput)\n",
    "prediction_mask = binary_mask(prediction)\n",
    "\n",
    "# show the mask using matplotlib\n",
    "plt.imshow(prediction_mask)\n",
    "\n",
    "# save the image as a png in google drive \n",
    "save_as_png(prediction_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_A few segmetation results of our example Model_**\n",
    "![results](https://raw.githubusercontent.com/marouaneloutfi/Rsbot/master/notebooks/images/results.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
