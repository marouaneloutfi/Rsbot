{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://www.group-cva.com/wp-content/themes/group_cva/media/logo_cva.svg)\n",
    "# Deep Learning in Remote Sensing\n",
    "### Introduction to Rsbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Rsbot?\n",
    "\n",
    "**_Rsbot is a python module designed to make Remote sensing with Google Earth Engine a lot easier._**\n",
    "    \n",
    "**_With extensibility at its core, Rsbot is a practical solution to building deeplearning pipelines._**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Main Features:\n",
    "* Construct Datasets arround Satellite imagery\n",
    "* Provides ready to use deep learning models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cropland classification demo\n",
    "\n",
    "**The Goal of this example is to identify crop types in fields using landsat8 satellite imagery.**\\\n",
    "**The architecture of our example is as follows**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_First we clone the github repository and install the required dependencies_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/marouaneloutfi/Rsbot.git\n",
    "!pip install -r Rsbot/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Import the classes and method we will be using for the Demo_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from Rsbot.gee.core import Gee, Landsat8\n",
    "from Rsbot.gee.crops import Crops\n",
    "from Rsbot.gee.utils import temp_concatenate\n",
    "from Rsbot.gee.dataset import Dataset\n",
    "from Rsbot.models.unet_3d import Unet3D\n",
    "from Rsbot.gee.tf_io import TfDatasetParser, binary_mask, binary_mask_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Initialize and authenticate to google earth engine through Rsbot Gee Class_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gee = Gee.get_instance(ipython=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Create a Landsat8 object to access and transform the Lansat8 satellite imagery_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "landsat = Landsat8('LANDSAT/LC08/C01/T1_SR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_The module should also come with a pre-defined wrapper classes for some popular Earth Engine datasets,\n",
    "For now we Have only one Dataset ready to use which is the [USDA](https://developers.google.com/earth-engine/datasets/catalog/USDA_NASS_CDL) NASS Cropland Data Layers._**\n",
    "\n",
    "\n",
    "**_This Data layer describes for each year crop-specific land cover for the entire country of  United States.\n",
    "for the purposes of this example, we are using the 2017 cropland layer to train our model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "crops = Crops(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_The USDA Cropland dataset comes with 254 predefined crop types._**\n",
    "\n",
    "\n",
    "**_In this example we want to train our model to identify 5 types only:_**\n",
    "\n",
    "    Corn, Soybeans, Alfalfa, Wheat and the Forrest landcover as well\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['corn', 'soybeans', 'alfalfa', 'wheat', 'forrest', 'background']\n",
    "crops_labels = crops.filter_labels(labels, thresh=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_To take into account the temporal changes that plants go through during their agricultral cycle,\n",
    "We use the following function to concatenate the satellite images of an 8 months period (an image for each month) and couple them with the landcover mask at the end._**\n",
    "\n",
    "\n",
    "**_The result is a GEE image of 64 bands (8 landsat bands * 8 monts ) plus the 6 labels _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "temporal_image = temp_concatenate(landsat, crops_labels, year=2017, kernel_size=KERNEL_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_We take two rectangular geometries each corresding to a geographical region in the United states and We use them to  create  our training and validation datasets by randomly sampling the previous GEE image over these regions_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(temporal_image, TRAINING_RECTANGLE, density=(0.5, 0.5), export_size=30)\n",
    "val_dataset = Dataset(temporal_image, VALIDATION_RECTANGLE, density=(0.1, 0.1), export_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Now that we have our datasets, we can iterate over them to download the samples directly to our Google drive account in mini batches as Tensorflow records._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, samples in  enumerate(iter(val_dataset)):\n",
    "    val_dataset.export_to_drive(samples, '', 'val_shard_'+str(i), folder=\"validation_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_We can check the status of the batches with the following line_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for batch in val_dataset.batches:\n",
    "    print([batch.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Once all of our samples have been downloaded as TF records. we load them into memorry as ready to use tensorlow Datasets using the Class TfDatasetParser_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/content/drive/My Drive/train_example/*.tfrecord.gz'\n",
    "val_dir = '/content/drive/My Drive/validation_example/*.tfrecord.gz'\n",
    "\n",
    "tf_parser = TfDatasetParser(KERNEL_SIZE, labels)\n",
    "\n",
    "train = tf_parser.get_dataset(train_dir, KERNEL_SIZE, shuffle=True)\n",
    "validation = tf_parser.get_dataset(val_dir, KERNEL_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Rsbot should come equipped with some popular segmentation and classification models. at the time of writing, Only 2 models have been implemented in Rsbot, both based on the Ecoder-decoder Unet archtitecture for sematic segmentation_**\n",
    "**_We initialize our Neural Network Model Unet3D and compile it._**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
